{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6e9fe3-a74b-45d6-bbad-bc33c3c98cfe",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "\n",
    "This notebook prepares the dataset for machine learning modeling.\n",
    "\n",
    "**Objectives:**\n",
    "- Separate features and target variable\n",
    "- Create train/validation/test splits\n",
    "- Build a preprocessing pipeline for numerical and categorical features\n",
    "- Handle missing values with business-justified strategy\n",
    "- Save the preprocessing pipeline for reproducibility\n",
    "\n",
    "**Key Principle:** All preprocessing is learned from training data only to prevent data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0001-0001-0001-000000000001",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75d7c5ec-c9bd-4e31-b29e-8616b095d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aac7516-7f67-45de-abcf-f905fa56a179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0           Electronic check          29.85         29.85     No  \n",
       "1               Mailed check          56.95       1889.50     No  \n",
       "2               Mailed check          53.85        108.15    Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75     No  \n",
       "4           Electronic check          70.70        151.65    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load prepared data\n",
    "df = pd.read_csv(\"../data/processed/telco_churn_prepared.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c7511-eea7-4bcd-a8a9-b50b50dfa2a9",
   "metadata": {},
   "source": [
    "## 2. Feature and Target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04645d71-e1b4-49c6-b180-24447368887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7043, 19)\n",
      "Target shape: (7043,)\n"
     ]
    }
   ],
   "source": [
    "# Define target and features\n",
    "target = \"Churn\"\n",
    "\n",
    "# Drop customerID (identifier) and target\n",
    "X = df.drop([target, \"customerID\"], axis=1)\n",
    "y = df[target]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49dd9ed2-dfb5-4d3f-ab16-c91d4767b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution before encoding:\n",
      "Churn\n",
      "No     5174\n",
      "Yes    1869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution after encoding:\n",
      "Churn\n",
      "0    5174\n",
      "1    1869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encode target variable (Yes=1, No=0)\n",
    "print(\"Target distribution before encoding:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "y = y.map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "print(\"\\nTarget distribution after encoding:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24444e0-9104-414f-89e0-79465c4de9dc",
   "metadata": {},
   "source": [
    "## 3. Train / Validation / Test Split\n",
    "\n",
    "**Split Strategy:**\n",
    "- Training set: 60% — for model training\n",
    "- Validation set: 20% — for model selection and hyperparameter tuning\n",
    "- Test set: 20% — for final unbiased evaluation\n",
    "\n",
    "**Important:** Stratified split to maintain class proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7b5aae8-9054-4adc-a29f-144c21613419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 60% train, 40% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.4,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 50% validation, 50% test (from temp)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ca132ef-829c-4a44-9068-c4445efe7b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Churn Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>4225</td>\n",
       "      <td>60.0</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>1409</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>1409</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set  Samples  Percentage  Churn Rate (%)\n",
       "0       Train     4225        60.0            26.5\n",
       "1  Validation     1409        20.0            26.5\n",
       "2        Test     1409        20.0            26.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: verify split sizes and class balance\n",
    "split_summary = []\n",
    "\n",
    "for name, X_set, y_set in [\n",
    "    (\"Train\", X_train, y_train),\n",
    "    (\"Validation\", X_val, y_val),\n",
    "    (\"Test\", X_test, y_test)\n",
    "]:\n",
    "    split_summary.append({\n",
    "        \"Set\": name,\n",
    "        \"Samples\": len(X_set),\n",
    "        \"Percentage\": round(len(X_set) / len(X) * 100, 1),\n",
    "        \"Churn Rate (%)\": round(y_set.mean() * 100, 1)\n",
    "    })\n",
    "\n",
    "pd.DataFrame(split_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98bf40c-6f53-4100-a2d4-ee0c8a5843a6",
   "metadata": {},
   "source": [
    "## 4. Feature Grouping\n",
    "\n",
    "Based on EDA findings, we group features by type for appropriate preprocessing.\n",
    "\n",
    "Note: SeniorCitizen is binary (0/1) but will be treated as categorical for one-hot encoding consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31bfd59b-2b4d-4b96-9bb8-2ac2f4702ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\n"
     ]
    }
   ],
   "source": [
    "# Numerical features\n",
    "numerical_features = [\n",
    "    \"tenure\",\n",
    "    \"MonthlyCharges\",\n",
    "    \"TotalCharges\"\n",
    "]\n",
    "\n",
    "print(f\"Numerical features ({len(numerical_features)}): {numerical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b04eb81e-33dc-4f15-9c19-ccedddbe2e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features (16):\n"
     ]
    }
   ],
   "source": [
    "# Categorical features (all columns not in numerical_features)\n",
    "categorical_features = [\n",
    "    col for col in X_train.columns\n",
    "    if col not in numerical_features\n",
    "]\n",
    "\n",
    "print(f\"Categorical features ({len(categorical_features)}):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b2c3d4-0004-0001-0001-000000000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features in X_train: 19\n",
      "Total features defined: 19\n",
      "Missing features: None\n",
      "Extra features: None\n"
     ]
    }
   ],
   "source": [
    "# Verify all features are accounted for\n",
    "all_features = numerical_features + categorical_features\n",
    "missing_features = set(X_train.columns) - set(all_features)\n",
    "extra_features = set(all_features) - set(X_train.columns)\n",
    "\n",
    "print(f\"Total features in X_train: {len(X_train.columns)}\")\n",
    "print(f\"Total features defined: {len(all_features)}\")\n",
    "print(f\"Missing features: {missing_features if missing_features else 'None'}\")\n",
    "print(f\"Extra features: {extra_features if extra_features else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4bf40-0f84-4aa4-87d3-b2bd5917c4d3",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Strategy\n",
    "\n",
    "### Design Decisions (Based on EDA)\n",
    "\n",
    "| Feature Type | Transformation | Rationale |\n",
    "|-------------|---------------|-----------|\n",
    "| Numerical | StandardScaler | Required for algorithms sensitive to feature scale |\n",
    "| Numerical (missing) | Impute with 0 + missing indicator | Missing values correspond to new customers (tenure = 0) |\n",
    "| Categorical | OneHotEncoder | No ordinal relationships identified |\n",
    "\n",
    "---\n",
    "\n",
    "### Missing Value Strategy\n",
    "\n",
    "- Missing values are observed **only in the `TotalCharges` feature**\n",
    "- These missing values correspond to **new customers who have not yet been billed**\n",
    "- Therefore, missingness is **not random** and carries meaningful business information\n",
    "- Strategy adopted:\n",
    "  - Impute missing values with `0`\n",
    "  - Add an explicit missing indicator column\n",
    "- This approach preserves the **\"not yet billed\" signal** while allowing models to learn from it\n",
    "\n",
    "---\n",
    "\n",
    "### Preprocessing Principles\n",
    "\n",
    "- All preprocessing steps are **learned exclusively from the training set**\n",
    "- The same transformations are applied consistently to validation and test sets\n",
    "- Preprocessing is implemented using a **reproducible scikit-learn pipeline**\n",
    "- This design prevents data leakage and ensures consistency across experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0005-0002-0001-000000000001",
   "metadata": {},
   "source": [
    "## 6. Build Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1757c5df-2333-4623-98bc-a97e7e772247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical transformer \n",
    "# - Impute missing values with 0 and add indicator column\n",
    "# - Apply standard scaling\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0, add_indicator=True)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1b2c3d4-0006-0001-0001-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical transformer\n",
    "# - OneHotEncoder for all categorical features\n",
    "# - handle_unknown='ignore' for robustness to unseen categories\n",
    "\n",
    "categorical_transformer = OneHotEncoder(\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False,\n",
    "    drop=None  # Keep all categories (no reference encoding)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d2a5969-c519-47b3-a559-fa75466d547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder=\"drop\",  # Drop any columns not specified\n",
    "    verbose_feature_names_out=False  # Cleaner feature names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0006-0002-0001-000000000001",
   "metadata": {},
   "source": [
    "## 7. Fit and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1b2c3d4-0007-0001-0001-000000000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor fitted on training data.\n"
     ]
    }
   ],
   "source": [
    "# Fit on training data ONLY (prevent data leakage)\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "print(\"Preprocessor fitted on training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1b2c3d4-0007-0002-0001-000000000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete:\n",
      "  X_train: (4225, 19) → (4225, 47)\n",
      "  X_val:   (1409, 19) → (1409, 47)\n",
      "  X_test:  (1409, 19) → (1409, 47)\n"
     ]
    }
   ],
   "source": [
    "# Transform all datasets\n",
    "X_train_processed = preprocessor.transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Transformation complete:\")\n",
    "print(f\"  X_train: {X_train.shape} → {X_train_processed.shape}\")\n",
    "print(f\"  X_val:   {X_val.shape} → {X_val_processed.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape} → {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1b2c3d4-0007-0003-0001-000000000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features after preprocessing: 47\n",
      "First 20 features:\n",
      " - tenure\n",
      " - MonthlyCharges\n",
      " - TotalCharges\n",
      " - missingindicator_TotalCharges\n",
      " - gender_Female\n",
      " - gender_Male\n",
      " - SeniorCitizen_0\n",
      " - SeniorCitizen_1\n",
      " - Partner_No\n",
      " - Partner_Yes\n",
      " - Dependents_No\n",
      " - Dependents_Yes\n",
      " - PhoneService_No\n",
      " - PhoneService_Yes\n",
      " - MultipleLines_No\n",
      " - MultipleLines_No phone service\n",
      " - MultipleLines_Yes\n",
      " - InternetService_DSL\n",
      " - InternetService_Fiber optic\n",
      " - InternetService_No\n"
     ]
    }
   ],
   "source": [
    "# Get feature names after transformation\n",
    "def get_feature_names(preprocessor, numerical_features, categorical_features):\n",
    "    \"\"\"Extract feature names from fitted ColumnTransformer.\"\"\"\n",
    "    feature_names = []\n",
    "    \n",
    "    # Numerical features (original + indicator if added)\n",
    "    num_transformer = preprocessor.named_transformers_['num']\n",
    "    imputer = num_transformer.named_steps['imputer']\n",
    "    \n",
    "    # Original numerical features\n",
    "    feature_names.extend(numerical_features)\n",
    "    \n",
    "    # Add indicator feature names if imputer created them\n",
    "    if hasattr(imputer, 'indicator_') and imputer.indicator_ is not None:\n",
    "        indicator_features = [f\"{feat}_missing\" for feat in numerical_features \n",
    "                             if imputer.indicator_.features_[0] == numerical_features.index(feat)\n",
    "                             or True]  # Simplified: add for all\n",
    "        # Get actual indicator features\n",
    "        n_indicators = imputer.indicator_.features_.shape[0] if hasattr(imputer.indicator_.features_, 'shape') else len(imputer.indicator_.features_)\n",
    "        indicator_features = [f\"{numerical_features[i]}_missing\" for i in imputer.indicator_.features_]\n",
    "        feature_names.extend(indicator_features)\n",
    "    \n",
    "    # Categorical features (one-hot encoded)\n",
    "    cat_transformer = preprocessor.named_transformers_['cat']\n",
    "    cat_feature_names = cat_transformer.get_feature_names_out(categorical_features)\n",
    "    feature_names.extend(cat_feature_names)\n",
    "    \n",
    "    return feature_names\n",
    "\n",
    "# Get feature names\n",
    "try:\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "except:\n",
    "    feature_names = get_feature_names(preprocessor, numerical_features, categorical_features)\n",
    "\n",
    "print(f\"Total features after preprocessing: {len(feature_names)}\")\n",
    "print(\"First 20 features:\")\n",
    "for f in feature_names[:20]:\n",
    "    print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0007-0004-0001-000000000001",
   "metadata": {},
   "source": [
    "## 8. Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1b2c3d4-0008-0001-0001-000000000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values after preprocessing:\n",
      "  X_train: 0\n",
      "  X_val:   0\n",
      "  X_test:  0\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining NaN values\n",
    "print(\"NaN values after preprocessing:\")\n",
    "print(f\"  X_train: {np.isnan(X_train_processed).sum()}\")\n",
    "print(f\"  X_val:   {np.isnan(X_val_processed).sum()}\")\n",
    "print(f\"  X_test:  {np.isnan(X_test_processed).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1b2c3d4-0008-0002-0001-000000000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Infinite values after preprocessing:\n",
      "  X_train: 0\n",
      "  X_val:   0\n",
      "  X_test:  0\n"
     ]
    }
   ],
   "source": [
    "# Check for any infinite values\n",
    "print(\"\\nInfinite values after preprocessing:\")\n",
    "print(f\"  X_train: {np.isinf(X_train_processed).sum()}\")\n",
    "print(f\"  X_val:   {np.isinf(X_val_processed).sum()}\")\n",
    "print(f\"  X_test:  {np.isinf(X_test_processed).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29581865-99b3-464a-8114-9c694f36df03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimensions:\n",
      "Train: (4225, 47)\n",
      "Validation: (1409, 47)\n",
      "Test: (1409, 47)\n"
     ]
    }
   ],
   "source": [
    "# Consistent number of features\n",
    "print(\"Feature dimensions:\")\n",
    "print(\"Train:\", X_train_processed.shape)\n",
    "print(\"Validation:\", X_val_processed.shape)\n",
    "print(\"Test:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0009-0001-0001-000000000001",
   "metadata": {},
   "source": [
    "## 9. Save Preprocessing Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59001a3c-02ad-44a9-b3b9-1e0509ed9d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessor saved to: /Users/omarpiro/churn_ml_decision/models/preprocessor.joblib\n",
      "✅ Feature names saved to: /Users/omarpiro/churn_ml_decision/models/feature_names.csv\n",
      "✅ Processed datasets saved:\n",
      "  - X_train_processed.npy\n",
      "  - X_val_processed.npy\n",
      "  - X_test_processed.npy\n",
      "  - y_train.npy\n",
      "  - y_val.npy\n",
      "  - y_test.npy\n",
      "ℹ️ Raw splits saved for audit/reference only\n"
     ]
    }
   ],
   "source": [
    "# Project root (we are inside /notebooks)\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "# Define paths\n",
    "MODELS_PATH = PROJECT_ROOT / \"models\"\n",
    "DATA_PROCESSED_PATH = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Create directories if needed\n",
    "MODELS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------\n",
    "# Save fitted preprocessor\n",
    "# ------------------------\n",
    "preprocessor_path = MODELS_PATH / \"preprocessor.joblib\"\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "\n",
    "print(f\"✅ Preprocessor saved to: {preprocessor_path}\")\n",
    "\n",
    "# ------------------------\n",
    "# Save feature names\n",
    "# ------------------------\n",
    "feature_names_df = pd.DataFrame({\n",
    "    \"feature\": feature_names\n",
    "})\n",
    "\n",
    "feature_names_path = MODELS_PATH / \"feature_names.csv\"\n",
    "feature_names_df.to_csv(feature_names_path, index=False)\n",
    "\n",
    "print(f\"✅ Feature names saved to: {feature_names_path}\")\n",
    "\n",
    "# ------------------------\n",
    "# Save processed datasets\n",
    "# ------------------------\n",
    "np.save(DATA_PROCESSED_PATH / \"X_train_processed.npy\", X_train_processed)\n",
    "np.save(DATA_PROCESSED_PATH / \"X_val_processed.npy\", X_val_processed)\n",
    "np.save(DATA_PROCESSED_PATH / \"X_test_processed.npy\", X_test_processed)\n",
    "\n",
    "np.save(DATA_PROCESSED_PATH / \"y_train.npy\", y_train.values)\n",
    "np.save(DATA_PROCESSED_PATH / \"y_val.npy\", y_val.values)\n",
    "np.save(DATA_PROCESSED_PATH / \"y_test.npy\", y_test.values)\n",
    "\n",
    "print(\"✅ Processed datasets saved:\")\n",
    "print(\"  - X_train_processed.npy\")\n",
    "print(\"  - X_val_processed.npy\")\n",
    "print(\"  - X_test_processed.npy\")\n",
    "print(\"  - y_train.npy\")\n",
    "print(\"  - y_val.npy\")\n",
    "print(\"  - y_test.npy\")\n",
    "\n",
    "# ------------------------\n",
    "#  Save raw splits for audit/debug\n",
    "# ------------------------\n",
    "X_train.to_csv(DATA_PROCESSED_PATH / \"X_train.csv\", index=False)\n",
    "X_val.to_csv(DATA_PROCESSED_PATH / \"X_val.csv\", index=False)\n",
    "X_test.to_csv(DATA_PROCESSED_PATH / \"X_test.csv\", index=False)\n",
    "\n",
    "y_train.to_csv(DATA_PROCESSED_PATH / \"y_train.csv\", index=False)\n",
    "y_val.to_csv(DATA_PROCESSED_PATH / \"y_val.csv\", index=False)\n",
    "y_test.to_csv(DATA_PROCESSED_PATH / \"y_test.csv\", index=False)\n",
    "\n",
    "print(\"ℹ️ Raw splits saved for audit/reference only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e43ab4-5f6f-430a-b02d-ba7d42cb6019",
   "metadata": {},
   "source": [
    "## 10. Preprocessing Summary\n",
    "\n",
    "### Pipeline Overview\n",
    "\n",
    "```\n",
    "Raw Data (19 features)\n",
    "        │\n",
    "        ▼\n",
    "┌───────────────────────────────────────────┐\n",
    "│           ColumnTransformer               │\n",
    "├───────────────────┬───────────────────────┤\n",
    "│  Numerical (3)    │  Categorical (16)     │\n",
    "│  ┌─────────────┐  │  ┌─────────────────┐  │\n",
    "│  │ Imputer     │  │  │ OneHotEncoder   │  │\n",
    "│  │ (0 + flag)  │  │  │                 │  │\n",
    "│  ├─────────────┤  │  │                 │  │\n",
    "│  │ Scaler      │  │  │                 │  │\n",
    "│  └─────────────┘  │  └─────────────────┘  │\n",
    "└───────────────────┴───────────────────────┘\n",
    "        │\n",
    "        ▼\n",
    "Processed Data (46 features)\n",
    "```\n",
    "\n",
    "### Transformations Applied\n",
    "\n",
    "| Feature Type | Transformation | Output |\n",
    "|-------------|----------------|--------|\n",
    "| Numerical (3) | Impute(0) + Indicator + Scale | 4 features (3 + 1 indicator) |\n",
    "| Categorical (16) | OneHotEncode | 42 features |\n",
    "| **Total** | | **46 features** |\n",
    "\n",
    "### Data Splits\n",
    "\n",
    "| Set | Samples | % | Churn Rate |\n",
    "|-----|---------|---|------------|\n",
    "| Train | 4,225 | 60% | 26.5% |\n",
    "| Validation | 1,409 | 20% | 26.5% |\n",
    "| Test | 1,409 | 20% | 26.5% |\n",
    "\n",
    "\n",
    "### Key Decisions\n",
    "\n",
    "1. **TotalCharges NaN handling**: Impute with 0 + indicator flag\n",
    "   - Preserves \"not yet billed\" signal for new customers\n",
    "   \n",
    "2. **No feature dropping**: All features kept (model can learn to ignore weak ones)\n",
    "\n",
    "3. **No ordinal encoding**: All categoricals one-hot encoded (no ordinal relationships)\n",
    "\n",
    "4. **Stratified splits**: Maintain class proportions across all sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1b2c3d4-0011-0001-0001-000000000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Input features:  19\n",
      "Output features: 47\n",
      "\n",
      "Training samples:   4,225\n",
      "Validation samples: 1,409\n",
      "Test samples:       1,409\n",
      "\n",
      "Preprocessor saved: /Users/omarpiro/churn_ml_decision/models/preprocessor.joblib\n",
      "\n",
      "Ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nInput features:  {X_train.shape[1]}\")\n",
    "print(f\"Output features: {X_train_processed.shape[1]}\")\n",
    "print(f\"\\nTraining samples:   {X_train_processed.shape[0]:,}\")\n",
    "print(f\"Validation samples: {X_val_processed.shape[0]:,}\")\n",
    "print(f\"Test samples:       {X_test_processed.shape[0]:,}\")\n",
    "print(f\"\\nPreprocessor saved: {preprocessor_path}\")\n",
    "print(\"\\nReady for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9a287-2f20-4141-b2f0-a94a61b66cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
